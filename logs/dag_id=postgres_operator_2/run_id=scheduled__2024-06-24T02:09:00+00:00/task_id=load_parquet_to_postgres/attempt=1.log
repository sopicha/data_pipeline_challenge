[2024-06-24T02:10:03.781+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-24T02:10:03.868+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: postgres_operator_2.load_parquet_to_postgres scheduled__2024-06-24T02:09:00+00:00 [queued]>
[2024-06-24T02:10:03.904+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: postgres_operator_2.load_parquet_to_postgres scheduled__2024-06-24T02:09:00+00:00 [queued]>
[2024-06-24T02:10:03.906+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 6
[2024-06-24T02:10:03.928+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): load_parquet_to_postgres> on 2024-06-24 02:09:00+00:00
[2024-06-24T02:10:03.938+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1071) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-24T02:10:03.942+0000] {standard_task_runner.py:63} INFO - Started process 1073 to run task
[2024-06-24T02:10:03.947+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'postgres_operator_2', 'load_parquet_to_postgres', 'scheduled__2024-06-24T02:09:00+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp0uatbh63']
[2024-06-24T02:10:03.952+0000] {standard_task_runner.py:91} INFO - Job 34: Subtask load_parquet_to_postgres
[2024-06-24T02:10:04.045+0000] {task_command.py:426} INFO - Running <TaskInstance: postgres_operator_2.load_parquet_to_postgres scheduled__2024-06-24T02:09:00+00:00 [running]> on host 18d040e2d413
[2024-06-24T02:10:04.222+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='postgres_operator_2' AIRFLOW_CTX_TASK_ID='load_parquet_to_postgres' AIRFLOW_CTX_EXECUTION_DATE='2024-06-24T02:09:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-06-24T02:09:00+00:00'
[2024-06-24T02:10:04.231+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-24T02:10:04.315+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.326+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.321+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.322+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.322+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.320+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.328+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.330+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.382+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.359+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.359+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.379+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.381+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.359+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.381+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:10:04.388+0000] {base.py:84} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-06-24T02:13:25.844+0000] {job.py:218} ERROR - Job heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: connection to server at "postgres" (192.168.48.3), port 5432 failed: FATAL:  sorry, too many clients already


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/jobs/job.py", line 192, in heartbeat
    self._merge_from(Job._fetch_from_db(self, session))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/retries.py", line 89, in wrapped_function
    for attempt in run_with_db_retries(max_retries=retries, logger=logger, **retry_kwargs):
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 435, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 368, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 410, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 183, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/retries.py", line 98, in wrapped_function
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/jobs/job.py", line 316, in _fetch_from_db
    session.merge(job)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3056, in merge
    return self._merge(
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 3136, in _merge
    merged = self.get(
             ^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2853, in get
    return self._get_impl(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2975, in _get_impl
    return db_load_fn(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/loading.py", line 530, in load_on_pk_identity
    session.execute(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (192.168.48.3), port 5432 failed: FATAL:  sorry, too many clients already

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-24T02:13:25.895+0000] {job.py:221} ERROR - Job heartbeat failed with error. Scheduler may go into unhealthy state
[2024-06-24T02:13:32.579+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:13:39.049+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:13:44.334+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:13:49.645+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:13:55.366+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:14:01.323+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:14:06.792+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:14:12.800+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:14:19.416+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:14:25.457+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:14:31.256+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:14:36.880+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:14:42.654+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:14:48.764+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:14:54.637+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:14:59.996+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:15:06.310+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:15:12.567+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:15:18.514+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:15:24.531+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:15:30.747+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:15:37.065+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:15:43.249+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:15:49.548+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:15:55.444+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:16:01.522+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:16:07.841+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:16:13.637+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:16:19.407+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:16:25.151+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:16:30.851+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:16:36.434+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:16:42.881+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:16:48.414+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:16:54.484+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:17:00.172+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:17:06.032+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:17:12.172+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:17:18.009+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:17:24.172+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:17:30.396+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:17:36.866+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:17:42.744+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:17:48.557+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:17:54.092+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:18:00.376+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:18:06.570+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:18:12.957+0000] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2024-06-24T02:18:49.207+0000] {local_task_job_runner.py:310} WARNING - State of this instance has been externally set to None. Terminating instance.
[2024-06-24T02:18:49.237+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-24T02:18:49.252+0000] {process_utils.py:132} INFO - Sending 15 to group 1073. PIDs of all processes in the group: [1073]
[2024-06-24T02:18:49.260+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 1073
[2024-06-24T02:18:49.392+0000] {taskinstance.py:2611} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-06-24T02:18:49.498+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-24T02:18:49.914+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/dag.py", line 43, in load_parquet_to_postgres
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 647, in __exit__
    self.shutdown(wait=True)
  File "/usr/local/lib/python3.12/concurrent/futures/thread.py", line 238, in shutdown
    t.join()
  File "/usr/local/lib/python3.12/threading.py", line 1147, in join
    self._wait_for_tstate_lock()
  File "/usr/local/lib/python3.12/threading.py", line 1167, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 2613, in signal_handler
    raise AirflowTaskTerminated("Task received SIGTERM signal")
airflow.exceptions.AirflowTaskTerminated: Task received SIGTERM signal
[2024-06-24T02:18:52.427+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=postgres_operator_2, task_id=load_parquet_to_postgres, run_id=scheduled__2024-06-24T02:09:00+00:00, execution_date=20240624T020900, start_date=20240624T021003, end_date=20240624T021852
[2024-06-24T02:18:53.069+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 34 for task load_parquet_to_postgres ((psycopg2.errors.ForeignKeyViolation) insert or update on table "task_fail" violates foreign key constraint "task_fail_ti_fkey"
DETAIL:  Key (dag_id, task_id, run_id, map_index)=(postgres_operator_2, load_parquet_to_postgres, scheduled__2024-06-24T02:09:00+00:00, -1) is not present in table "task_instance".

[SQL: INSERT INTO task_fail (task_id, dag_id, run_id, map_index, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(run_id)s, %(map_index)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'load_parquet_to_postgres', 'dag_id': 'postgres_operator_2', 'run_id': 'scheduled__2024-06-24T02:09:00+00:00', 'map_index': -1, 'start_date': datetime.datetime(2024, 6, 24, 2, 10, 3, 871081, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2024, 6, 24, 2, 18, 52, 167446, tzinfo=Timezone('UTC')), 'duration': 528}]
(Background on this error at: https://sqlalche.me/e/14/gkpj); 1073)
[2024-06-24T02:18:53.295+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=1073, status='terminated', exitcode=1, started='02:10:03') (1073) terminated with exit code 1
